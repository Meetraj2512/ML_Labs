{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1TjYSso4CjoXgj-uEe2RP8ee6dwAT_rnp","authorship_tag":"ABX9TyPoBkBVO3Yy47rmZMmZgvpF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **LAB 08 : ENSEMBLE LEARNING**\n","\n"],"metadata":{"id":"8qRUfCqkY7QF"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score   "],"metadata":{"id":"iaGRg5zlZBMk","executionInfo":{"status":"ok","timestamp":1675414218878,"user_tz":-330,"elapsed":466,"user":{"displayName":"CE068_Meetraj_Desai","userId":"15785813160065590553"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### **Implementation of stacking , with max voting as classification model**"],"metadata":{"id":"1bXDFuEpdxsc"}},{"cell_type":"code","source":["def max_voting(output):\n","  votes={}\n","  for elem in output:\n","    if elem in votes:\n","      votes[elem]+=1\n","    else :\n","      votes[elem]=1\n","  final_output=-1\n","  max_votes=-1\n","  for elem in votes:\n","    if max_votes<votes[elem]:\n","      max_votes=votes[elem]\n","      final_output=elem\n","      pass\n","    pass\n","  print(votes)\n","  return final_output,max_votes\n","  pass\n","\n","\n","def get_data_set():\n","  weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n","  temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n","  play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n","  le=preprocessing.LabelEncoder()\n","  weather_encoded=le.fit_transform(weather)\n","  temp_encoded=le.fit_transform(temp)\n","  play_encoded=le.fit_transform(play)\n","  features=tuple(zip(weather_encoded,temp_encoded))\n","  return features,play_encoded\n","  pass\n","\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    \n","    new_model=CategoricalNB(alpha=1)\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LogisticRegression(random_state=0).fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","\n","def get_accuracy(y_pred,y_test):\n","  \n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","x,y=get_data_set() \n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50) \n","meta_classifier=get_meta_classifier(x_train,y_train)\n","y_pred=meta_classifier.predict(x_test)\n","print(y_pred)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxBXehyhdvpd","executionInfo":{"status":"ok","timestamp":1675414365122,"user_tz":-330,"elapsed":479,"user":{"displayName":"CE068_Meetraj_Desai","userId":"15785813160065590553"}},"outputId":"2b108b63-715f-43ae-a353-941b77bbbacf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 0 0]\n","accuracy :  0.7142857142857143\n"]}]},{"cell_type":"markdown","source":["### **Stacking using regression and low diabetes database**"],"metadata":{"id":"DWK1xOTEeIMG"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_diabetes\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","\n","# def max_voting(output):\n","#   votes={}\n","#   for elem in output:\n","#     if elem in votes:\n","#       votes[elem]+=1\n","#     else :\n","#       votes[elem]=1\n","  \n","#   final_output=-1\n","#   max_votes=-1\n","#   for elem in votes:\n","#     if max_votes<votes[elem]:\n","#       max_votes=votes[elem]\n","#       final_output=elem\n","#       pass\n","#     pass\n","#   print(votes)\n","#   return final_output,max_votes\n","#   pass\n","\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_diabetes()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    new_model=LinearRegression()\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LinearRegression().fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","\n","def get_mse(y_pred,y_test):\n","  return mean_squared_error(y_pred,y_test)\n","  pass\n","\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","meta_classifier=get_meta_classifier(x_train,y_train)\n","y_pred=meta_classifier.predict(x_test)\n","print(\"mse loss : \",get_mse(y_pred,y_test))\n","# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n","# print(x_1,y_1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kEcqSdqeKm3","executionInfo":{"status":"ok","timestamp":1675414277472,"user_tz":-330,"elapsed":482,"user":{"displayName":"CE068_Meetraj_Desai","userId":"15785813160065590553"}},"outputId":"5b7ed893-dd28-4614-a7a5-62876f5f78c7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["mse loss :  2679.3209640213354\n"]}]},{"cell_type":"markdown","source":["### **Adaboost classifier**"],"metadata":{"id":"QOB_SC6BfAb0"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import confusion_matrix\n","\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","\n","def get_classifier(x,y):\n","  return AdaBoostClassifier().fit(x,y)\n","\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of addboostclassification\")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NygCA4TgfFvV","executionInfo":{"status":"ok","timestamp":1675414508782,"user_tz":-330,"elapsed":497,"user":{"displayName":"CE068_Meetraj_Desai","userId":"15785813160065590553"}},"outputId":"3178a244-431f-4ed2-a164-051882100ff0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9789473684210527\n","confusion matrix of addboostclassification\n","[[103   2]\n"," [  4 176]]\n"]}]},{"cell_type":"markdown","source":["### **Use StackingClassifier from sklearn to implement the same on cancer dataset**"],"metadata":{"id":"Pn183je5fKNz"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","\n","def get_classifier(x,y):\n","  return BaggingClassifier().fit(x,y)\n","\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of bagging on descision tree classifier : \")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7htqbA7KfNJ6","executionInfo":{"status":"ok","timestamp":1675417770635,"user_tz":-330,"elapsed":478,"user":{"displayName":"CE068_Meetraj_Desai","userId":"15785813160065590553"}},"outputId":"3ab78025-f6ac-4574-afdb-b74ec47c3219"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9543859649122807\n","confusion matrix of bagging on descision tree classifier : \n","[[100   6]\n"," [  7 172]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"H8PdPYf2rt0O"},"execution_count":null,"outputs":[]}]}